<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "https://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en-US">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=11"/>
<meta name="generator" content="Doxygen 1.11.0"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>Daves Coding Paradise: DCL::CNeuralNetworkFeedForward Class Reference</title>
<link rel="icon" href="DCP_icon.PNG" type="image/x-icon" />
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<script type="text/javascript" src="clipboard.js"></script>
<link href="navtree.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="navtreedata.js"></script>
<script type="text/javascript" src="navtree.js"></script>
<script type="text/javascript" src="resize.js"></script>
<script type="text/javascript" src="cookie.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr id="projectrow">
  <td id="projectlogo"><img alt="Logo" src="DCP_logo.PNG"/></td>
  <td id="projectalign">
   <div id="projectname">Daves Coding Paradise<span id="projectnumber">&#160;0.1.1</span>
   </div>
   <div id="projectbrief">Daves Coding Paradise</div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.11.0 -->
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
var searchBox = new SearchBox("searchBox", "search/",'.html');
/* @license-end */
</script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
$(function() { codefold.init(0); });
/* @license-end */
</script>
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
$(function() {
  initMenu('',true,false,'search.php','Search',true);
  $(function() { init_search(); });
});
/* @license-end */
</script>
<div id="main-nav"></div>
</div><!-- top -->
<div id="side-nav" class="ui-resizable side-nav-resizable">
  <div id="nav-tree">
    <div id="nav-tree-contents">
      <div id="nav-sync" class="sync"></div>
    </div>
  </div>
  <div id="splitbar" style="-moz-user-select:none;" 
       class="ui-resizable-handle">
  </div>
</div>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
$(function(){initNavTree('class_d_c_l_1_1_c_neural_network_feed_forward.html',''); initResizable(true); });
/* @license-end */
</script>
<div id="doc-content">
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<div id="MSearchResults">
<div class="SRPage">
<div id="SRIndex">
<div id="SRResults"></div>
<div class="SRStatus" id="Loading">Loading...</div>
<div class="SRStatus" id="Searching">Searching...</div>
<div class="SRStatus" id="NoMatches">No Matches</div>
</div>
</div>
</div>
</div>

<div class="header">
  <div class="summary">
<a href="#pub-methods">Public Member Functions</a> &#124;
<a href="class_d_c_l_1_1_c_neural_network_feed_forward-members.html">List of all members</a>  </div>
  <div class="headertitle"><div class="title">DCL::CNeuralNetworkFeedForward Class Reference</div></div>
</div><!--header-->
<div class="contents">

<p>This is a "feed forward" neural network.  
 <a href="#details">More...</a></p>

<p><code>#include &lt;<a class="el" href="_neural_net_feed_forward_8h_source.html">NeuralNetFeedForward.h</a>&gt;</code></p>
<table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a id="pub-methods" name="pub-methods"></a>
Public Member Functions</h2></td></tr>
<tr class="memitem:a7a637bc9b034c071daab0e917bbd18a2" id="r_a7a637bc9b034c071daab0e917bbd18a2"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#a7a637bc9b034c071daab0e917bbd18a2">CNeuralNetworkFeedForward</a> ()</td></tr>
<tr class="memdesc:a7a637bc9b034c071daab0e917bbd18a2"><td class="mdescLeft">&#160;</td><td class="mdescRight">Constructor.  <br /></td></tr>
<tr class="separator:a7a637bc9b034c071daab0e917bbd18a2"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a9beb7ce0130efd7b63a802a255003856" id="r_a9beb7ce0130efd7b63a802a255003856"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#a9beb7ce0130efd7b63a802a255003856">CNeuralNetworkFeedForward</a> (int iNumInputs, int iNumOutputs, int iNumLayers, int iNumNeuronsPerLayer)</td></tr>
<tr class="memdesc:a9beb7ce0130efd7b63a802a255003856"><td class="mdescLeft">&#160;</td><td class="mdescRight">Constructor.  <br /></td></tr>
<tr class="separator:a9beb7ce0130efd7b63a802a255003856"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:acb77c7337cf1440793b45b312aa2dac4" id="r_acb77c7337cf1440793b45b312aa2dac4"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#acb77c7337cf1440793b45b312aa2dac4">create</a> (int iNumInputs, int iNumOutputs, int iNumLayers, int iNumNeuronsPerLayer)</td></tr>
<tr class="memdesc:acb77c7337cf1440793b45b312aa2dac4"><td class="mdescLeft">&#160;</td><td class="mdescRight">Creates/recreates the network.  <br /></td></tr>
<tr class="separator:acb77c7337cf1440793b45b312aa2dac4"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a9082844ff1fbbb3890d468c4acf3bd15" id="r_a9082844ff1fbbb3890d468c4acf3bd15"><td class="memItemLeft" align="right" valign="top">std::vector&lt; double &gt;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#a9082844ff1fbbb3890d468c4acf3bd15">getNeuronWeights</a> (void) const</td></tr>
<tr class="memdesc:a9082844ff1fbbb3890d468c4acf3bd15"><td class="mdescLeft">&#160;</td><td class="mdescRight">Returns a vector holding all the weights of all the neurons in each of the layers, including the output layer.  <br /></td></tr>
<tr class="separator:a9082844ff1fbbb3890d468c4acf3bd15"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:af9100130b7f3c95cb02d9d59515388fa" id="r_af9100130b7f3c95cb02d9d59515388fa"><td class="memItemLeft" align="right" valign="top">int&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#af9100130b7f3c95cb02d9d59515388fa">getNumberOfWeights</a> (void) const</td></tr>
<tr class="memdesc:af9100130b7f3c95cb02d9d59515388fa"><td class="mdescLeft">&#160;</td><td class="mdescRight">Returns the number of weights of all the neurons in each of the layers, including the output layer.  <br /></td></tr>
<tr class="separator:af9100130b7f3c95cb02d9d59515388fa"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a5c907e87498ba77d90844fce32e4375d" id="r_a5c907e87498ba77d90844fce32e4375d"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#a5c907e87498ba77d90844fce32e4375d">replaceWeights</a> (const std::vector&lt; double &gt; &amp;newWeights)</td></tr>
<tr class="memdesc:a5c907e87498ba77d90844fce32e4375d"><td class="mdescLeft">&#160;</td><td class="mdescRight">Replaces the weights of all the neurons in each of the layers with the ones given.  <br /></td></tr>
<tr class="separator:a5c907e87498ba77d90844fce32e4375d"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a703b5d1758980e9365bd3be29525dd68" id="r_a703b5d1758980e9365bd3be29525dd68"><td class="memItemLeft" align="right" valign="top">std::vector&lt; double &gt;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#a703b5d1758980e9365bd3be29525dd68">update</a> (std::vector&lt; double &gt; &amp;vecInputs)</td></tr>
<tr class="memdesc:a703b5d1758980e9365bd3be29525dd68"><td class="mdescLeft">&#160;</td><td class="mdescRight">Given a vector of inputs, updates the neural network and returns the output values.  <br /></td></tr>
<tr class="separator:a703b5d1758980e9365bd3be29525dd68"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a28acb02d9185de77b5f480ac074622f2" id="r_a28acb02d9185de77b5f480ac074622f2"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#a28acb02d9185de77b5f480ac074622f2">setWeightBias</a> (double dWeightBias=-1)</td></tr>
<tr class="memdesc:a28acb02d9185de77b5f480ac074622f2"><td class="mdescLeft">&#160;</td><td class="mdescRight">Sets the bias which is used during update when computing the output for a neuron (weight * input) * bias.  <br /></td></tr>
<tr class="separator:a28acb02d9185de77b5f480ac074622f2"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a22e7d0f6ac35cad6149524a4db5971f1" id="r_a22e7d0f6ac35cad6149524a4db5971f1"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#a22e7d0f6ac35cad6149524a4db5971f1">setSigmoidResponse</a> (double dResponse=1)</td></tr>
<tr class="memdesc:a22e7d0f6ac35cad6149524a4db5971f1"><td class="mdescLeft">&#160;</td><td class="mdescRight">Sets the response value used by the sigmoid function which sets the shape of the curve produced from the sigmoid function.  <br /></td></tr>
<tr class="separator:a22e7d0f6ac35cad6149524a4db5971f1"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a7bbc7c1e261995931e9076f06a1d0a81" id="r_a7bbc7c1e261995931e9076f06a1d0a81"><td class="memItemLeft" align="right" valign="top">std::vector&lt; int &gt;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#a7bbc7c1e261995931e9076f06a1d0a81">calculateSplitPoints</a> (void)</td></tr>
<tr class="memdesc:a7bbc7c1e261995931e9076f06a1d0a81"><td class="mdescLeft">&#160;</td><td class="mdescRight">Calculate splits points used by the genetic algorithm training class.  <br /></td></tr>
<tr class="separator:a7bbc7c1e261995931e9076f06a1d0a81"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table>
<a name="details" id="details"></a><h2 class="groupheader">Detailed Description</h2>
<div class="textblock"><p>This is a "feed forward" neural network. </p>
<p>A feed forward neural network is one whereby the inputs go into the network and move along in one direction towards the outputs. The advantages of this is speed. The disadvantages is that it is not as complex. A neural network, regardless of it's type, simulates connections and firings between neurons in a biological brain.</p>
<p>Here's a short list of animals and the approximate number of neurons within their minds... Killer whale: 43 100 000 000 Dolphin: 18 750 000 000 Human: 16 340 000 000 Bottlenose dolphin: 12 700 000 000 Gorilla (Western): 9 100 000 000 Asian elephant: 6 775 000 000 Red and green macaw: 2 646 000 000 Giraffe: 1 731 000 000 Snowy old: 1 270 000 000 German shepherd: 885 460 000 Lion: 545 240 000 Pig: 425 000 000 Brown bear: 250 970 000 House cat: 249 830 000 Mallard duck: 112 255 000 Common wood pigeon: 51 325 000 Brown rat: 31 000 000 Golden hamster: 17 000 000 Bat: 6 000 000 Ant: 250 000 Cockroach: 200 000 Honey bee: 170 000 Cricket: 50 000 Jelly fish: 5 600 Common fruit fly: 2 500 Starfish: 500 Tardigrade: 200 Sea sponge: 0</p>
<p>We won't be simulating the mind of a killer whale any time soon, but the above list gives us an insight into how complex these creatures' minds are.</p>
<p>In a human mind, each neuron is connected via its dendrites to approximately 10,000 other neurons. This means that it's possible to have 1,000,000,000,000,000 connections!</p>
<p>A brain’s neurons either fire or they don’t. The strength of the emitted signal does not vary, only the frequency. The neuron sums all the incoming signals from the synapses and if the total signal exceeds a threshold value, the neuron fires and an electrical signal is sent shooting down the axon. Also, each neuron operates at around 100Hz.</p>
<p>Obviously, we can't use millions of neurons, but with a number as small as just ten, we are able to get some incredibly interesting behaviour.</p>
<p>The great thing about all these neurons is that they are great for generalizing. and if trained well, can exhibit fantastic creature like behaviour. Neural networks are commonly used for pattern recognition. This is because they are great at mapping an input state (the pattern it’s trying to recognize) to an output state (the pattern it has been trained to recognize)</p>
<p>Let’s take the example of character recognition. Imagine an LED panel made up of a grid of lights 8×8. Each light can be on or off, so the panel can be used to display the numbers 0 through to 9. To solve the problem, a network must be designed which will accept the state of the panel as an input and then output either a one or a zero. A one to indicate that, for example, the character 7 is being displayed and zero if it thinks it is not. The neural net will have 64 inputs, a layer of neurons, all feeding their output into just one neuron in the output layer. Once the neural network has been setup with the inputs, layers and output, it must be trained to recognize the character 7. One way of doing this is to initialize the neural net with random weights and then feed it a series of inputs which represent the different characters shown on the panel. For each character, we check to see what it's output is and adjust the weights accordingly. If the input pattern we feed it is not a 7, then we know the neural network should output a zero. So for every non 7 character, the weights are adjusted slightly so the output tends toward zero. When it’s presented with a pattern that represents the character 7, the weights are adjusted so the output tends toward the number one.</p>
<p>We could increase the number of outputs to ten. Then it would be possible to train the network to recognize all the digits 0 through 9. But let's go even more nuts! Let’s increase the outputs so the entire alphabet can be recognized. This is how handwriting recognition works. For each character, the network is trained to recognize many different versions of a letter. Eventually the network will not only be able to recognize the letters it has been trained with, but it will also be able to generalize. That is, if a letter is drawn slightly differently from the letters used during training, the network will stand a pretty good chance of recognizing it.</p>
<p>Not only can a network be used for recognition of characters, but any type of image. People's faces, photos of animals or objects. A network can also even be used for horse racing prediction and, interesting to us, game object navigation (flocking, avoidance, moving towards food, away from enemies) and more!</p>
<p>This type of network training is called "Supervised training" and the data used to train it is called a "training set".</p>
<p>Now let's get back to programming... We simulate all these neurons and their connections (On a much smaller scale) within this class. Each neuron can have inputs which are either on or off, 0 or 1 and they are scaled by a weight. Each of these weights are summed by their connected neuron and if the sum is over a certain threshold, the neuron fires. Just like a biological neuron, kinda:) The inputs can be positive or negative so can contribute towards or against a neuron firing. A feed forward network has it's inputs at one end and then one or more layers of neurons, with the initial layer taking and summing the inputs, firing or not and then sending that onto the next layer of neurons until the final layer is reached. Each neuron in each layer is connected to each and every neuron in the next layer. The outputs of the final neuron layer are then retrieved by use to interprete however we choose.</p>
<p>The outputs of a network are either 0 or 1, however, we can modify them so that the output is S shaped, with the values being around 0.5. To do this, we use a sigma function, sigma being a Greek word for something which is S shaped. We can then use these modified output values as anything we like, for example, the amount of rotation around an axis, or velocity increase/decrease, or whether to fire a weapon and more.</p>
<p>When using the sigmoid method, it requires a value named response. This modifies the curve of the output value and is typically set to 1. Larger values produce a smoother curve where the values tend towards a straight line, whereas smaller values produce a tighter curve where the value centres more towards 0.5.</p>
<p>When choosing which inputs to use, the fewer the better because the network won't have to "work as hard" to find a relationship between them all. So for example, if we're trying to make some game entity move towards certain objects, instead of specifying lots of inputs such as entity positions(x and y), vectors towards the objects (also x,y) and the entity's direction vector (another x and y), we could more efficiently give the network just a single float for it's rotation and a single float which represents the angle between the rotation of the entity and the object instead. These fewer inputs still represent all the information needed, but as there are less of them, the network will be able to find the relationship between them easier. And with this, the network can contain fewer neurons and be faster to compute as a result.</p>
<p>Inputs should each be given, which are around the same scale, for example if a vector was given to a target and it wasn't normalized, and another input was given, perhaps say the entity's normalized direction vector, the vector with the larger magnitude would have a much greater impact on the neural network than the entity's direction vector and as a result, the network may have a really hard time trying to find a relationship between them. Another great tip is that sometimes, centering the inputs around zero give better results.</p>
<p>What about the number of neurons and number of layers? What should we choose there? It's pretty much down to trial and error and getting a feel for how the network is behaving. Typically, one layer is enough. As for the number of neurons, yup, same again, trial and error. However, too few and the network won't stand a chance at giving good outputs and too many, well, it'll be OK, but it will be slower to compute.</p>
<p>So with all that out of the way, how do we actually use them? We create a network, choosing the number of inputs we'll give it, the number of layers, the number of neurons in each layer and the number of outputs. We then use another class, to train the network. Then once the we've found networks which perform as we wish, we can then save those best performing networks to a file. Then in our game/program, we can create a network, for each entity in our program, load the networks weights and configuration from the file and then update it, passing it it's input we used during training and getting the outputs and applying those the same we did during training, nice.</p>
<p>At the moment, the training class we use is in <a class="el" href="_genetic_algorithm_8h_source.html">geneticAlgorithm.h</a>/cpp, go there to see more detail on how we train the networks. </p>

<p class="definition">Definition at line <a class="el" href="_neural_net_feed_forward_8h_source.html#l00194">194</a> of file <a class="el" href="_neural_net_feed_forward_8h_source.html">NeuralNetFeedForward.h</a>.</p>
</div><h2 class="groupheader">Constructor &amp; Destructor Documentation</h2>
<a id="a7a637bc9b034c071daab0e917bbd18a2" name="a7a637bc9b034c071daab0e917bbd18a2"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a7a637bc9b034c071daab0e917bbd18a2">&#9670;&#160;</a></span>CNeuralNetworkFeedForward() <span class="overload">[1/2]</span></h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">DCL::CNeuralNetworkFeedForward::CNeuralNetworkFeedForward </td>
          <td>(</td>
          <td class="paramname"><span class="paramname"><em></em></span></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Constructor. </p>
<p>Sets to default values. </p>

<p class="definition">Definition at line <a class="el" href="_neural_net_feed_forward_8cpp_source.html#l00027">27</a> of file <a class="el" href="_neural_net_feed_forward_8cpp_source.html">NeuralNetFeedForward.cpp</a>.</p>

</div>
</div>
<a id="a9beb7ce0130efd7b63a802a255003856" name="a9beb7ce0130efd7b63a802a255003856"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a9beb7ce0130efd7b63a802a255003856">&#9670;&#160;</a></span>CNeuralNetworkFeedForward() <span class="overload">[2/2]</span></h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">DCL::CNeuralNetworkFeedForward::CNeuralNetworkFeedForward </td>
          <td>(</td>
          <td class="paramtype">int</td>          <td class="paramname"><span class="paramname"><em>iNumInputs</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int</td>          <td class="paramname"><span class="paramname"><em>iNumOutputs</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int</td>          <td class="paramname"><span class="paramname"><em>iNumLayers</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int</td>          <td class="paramname"><span class="paramname"><em>iNumNeuronsPerLayer</em></span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Constructor. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">iNumInputs</td><td>The number of inputs this network will have. </td></tr>
    <tr><td class="paramname">iNumOutputs</td><td>The number of outputs this network will have. </td></tr>
    <tr><td class="paramname">iNumLayers</td><td>The number of neuron layers this network will have. </td></tr>
    <tr><td class="paramname">iNumNeuronsPerLayer</td><td>The number of neurons per layer this network will have.</td></tr>
  </table>
  </dd>
</dl>
<p>Sets values to the ones given </p>

<p class="definition">Definition at line <a class="el" href="_neural_net_feed_forward_8cpp_source.html#l00033">33</a> of file <a class="el" href="_neural_net_feed_forward_8cpp_source.html">NeuralNetFeedForward.cpp</a>.</p>

</div>
</div>
<h2 class="groupheader">Member Function Documentation</h2>
<a id="a7bbc7c1e261995931e9076f06a1d0a81" name="a7bbc7c1e261995931e9076f06a1d0a81"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a7bbc7c1e261995931e9076f06a1d0a81">&#9670;&#160;</a></span>calculateSplitPoints()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">std::vector&lt; int &gt; DCL::CNeuralNetworkFeedForward::calculateSplitPoints </td>
          <td>(</td>
          <td class="paramtype">void</td>          <td class="paramname"><span class="paramname"><em></em></span></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Calculate splits points used by the genetic algorithm training class. </p>
<dl class="section return"><dt>Returns</dt><dd>A vector of ints holding the split points between individual neurons.</dd></dl>
<p>This returns points in the weights vector which are spaced out between each neuron. This makes it so that when we split the weights of the parents, when creating child networks, the splits are between neurons, rather than ANY position which could be between some of the weights of a single neuron. If this happened, that individual neuron when passed on to the child, could be considered "mutated", as we are not passing on a whole neuron, only a part of it. </p>

<p class="definition">Definition at line <a class="el" href="_neural_net_feed_forward_8cpp_source.html#l00202">202</a> of file <a class="el" href="_neural_net_feed_forward_8cpp_source.html">NeuralNetFeedForward.cpp</a>.</p>

</div>
</div>
<a id="acb77c7337cf1440793b45b312aa2dac4" name="acb77c7337cf1440793b45b312aa2dac4"></a>
<h2 class="memtitle"><span class="permalink"><a href="#acb77c7337cf1440793b45b312aa2dac4">&#9670;&#160;</a></span>create()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">void DCL::CNeuralNetworkFeedForward::create </td>
          <td>(</td>
          <td class="paramtype">int</td>          <td class="paramname"><span class="paramname"><em>iNumInputs</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int</td>          <td class="paramname"><span class="paramname"><em>iNumOutputs</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int</td>          <td class="paramname"><span class="paramname"><em>iNumLayers</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int</td>          <td class="paramname"><span class="paramname"><em>iNumNeuronsPerLayer</em></span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Creates/recreates the network. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">iNumInputs</td><td>The number of inputs this network will have. </td></tr>
    <tr><td class="paramname">iNumOutputs</td><td>The number of outputs this network will have. </td></tr>
    <tr><td class="paramname">iNumLayers</td><td>The number of neuron layers this network will have. </td></tr>
    <tr><td class="paramname">iNumNeuronsPerLayer</td><td>The number of neurons per layer this network will have. </td></tr>
  </table>
  </dd>
</dl>

<p class="definition">Definition at line <a class="el" href="_neural_net_feed_forward_8cpp_source.html#l00038">38</a> of file <a class="el" href="_neural_net_feed_forward_8cpp_source.html">NeuralNetFeedForward.cpp</a>.</p>

</div>
</div>
<a id="a9082844ff1fbbb3890d468c4acf3bd15" name="a9082844ff1fbbb3890d468c4acf3bd15"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a9082844ff1fbbb3890d468c4acf3bd15">&#9670;&#160;</a></span>getNeuronWeights()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">std::vector&lt; double &gt; DCL::CNeuralNetworkFeedForward::getNeuronWeights </td>
          <td>(</td>
          <td class="paramtype">void</td>          <td class="paramname"><span class="paramname"><em></em></span></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Returns a vector holding all the weights of all the neurons in each of the layers, including the output layer. </p>
<dl class="section return"><dt>Returns</dt><dd>A vector holding all the weights of this network. </dd></dl>

<p class="definition">Definition at line <a class="el" href="_neural_net_feed_forward_8cpp_source.html#l00084">84</a> of file <a class="el" href="_neural_net_feed_forward_8cpp_source.html">NeuralNetFeedForward.cpp</a>.</p>

</div>
</div>
<a id="af9100130b7f3c95cb02d9d59515388fa" name="af9100130b7f3c95cb02d9d59515388fa"></a>
<h2 class="memtitle"><span class="permalink"><a href="#af9100130b7f3c95cb02d9d59515388fa">&#9670;&#160;</a></span>getNumberOfWeights()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">int DCL::CNeuralNetworkFeedForward::getNumberOfWeights </td>
          <td>(</td>
          <td class="paramtype">void</td>          <td class="paramname"><span class="paramname"><em></em></span></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Returns the number of weights of all the neurons in each of the layers, including the output layer. </p>
<dl class="section return"><dt>Returns</dt><dd>The number of weights in this network. </dd></dl>

<p class="definition">Definition at line <a class="el" href="_neural_net_feed_forward_8cpp_source.html#l00104">104</a> of file <a class="el" href="_neural_net_feed_forward_8cpp_source.html">NeuralNetFeedForward.cpp</a>.</p>

</div>
</div>
<a id="a5c907e87498ba77d90844fce32e4375d" name="a5c907e87498ba77d90844fce32e4375d"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a5c907e87498ba77d90844fce32e4375d">&#9670;&#160;</a></span>replaceWeights()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">void DCL::CNeuralNetworkFeedForward::replaceWeights </td>
          <td>(</td>
          <td class="paramtype">const std::vector&lt; double &gt; &amp;</td>          <td class="paramname"><span class="paramname"><em>newWeights</em></span></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Replaces the weights of all the neurons in each of the layers with the ones given. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">newWeights</td><td>A vector of doubles which hold the values of the new weights. </td></tr>
  </table>
  </dd>
</dl>

<p class="definition">Definition at line <a class="el" href="_neural_net_feed_forward_8cpp_source.html#l00123">123</a> of file <a class="el" href="_neural_net_feed_forward_8cpp_source.html">NeuralNetFeedForward.cpp</a>.</p>

</div>
</div>
<a id="a22e7d0f6ac35cad6149524a4db5971f1" name="a22e7d0f6ac35cad6149524a4db5971f1"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a22e7d0f6ac35cad6149524a4db5971f1">&#9670;&#160;</a></span>setSigmoidResponse()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">void DCL::CNeuralNetworkFeedForward::setSigmoidResponse </td>
          <td>(</td>
          <td class="paramtype">double</td>          <td class="paramname"><span class="paramname"><em>dResponse</em></span><span class="paramdefsep"> = </span><span class="paramdefval">1</span></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Sets the response value used by the sigmoid function which sets the shape of the curve produced from the sigmoid function. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">dResponse</td><td>The response value used by the sigmoid function which sets the shape of the curve produced from the sigmoid function.</td></tr>
  </table>
  </dd>
</dl>
<p>Higher values, flatten the curve, lower ones tighten it. A default value of 1 is usually used. Do not set it to zero, this'll create a divide by zero error. (Actually, an exception occurs) </p>

<p class="definition">Definition at line <a class="el" href="_neural_net_feed_forward_8cpp_source.html#l00196">196</a> of file <a class="el" href="_neural_net_feed_forward_8cpp_source.html">NeuralNetFeedForward.cpp</a>.</p>

</div>
</div>
<a id="a28acb02d9185de77b5f480ac074622f2" name="a28acb02d9185de77b5f480ac074622f2"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a28acb02d9185de77b5f480ac074622f2">&#9670;&#160;</a></span>setWeightBias()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">void DCL::CNeuralNetworkFeedForward::setWeightBias </td>
          <td>(</td>
          <td class="paramtype">double</td>          <td class="paramname"><span class="paramname"><em>dWeightBias</em></span><span class="paramdefsep"> = </span><span class="paramdefval">-1</span></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Sets the bias which is used during update when computing the output for a neuron (weight * input) * bias. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">dWeightBias</td><td>The bias used during updating the network and computing the output for each of it's neurons (weight * input) * bias.</td></tr>
  </table>
  </dd>
</dl>
<p>This is typically set to -1 and left alone. </p>

<p class="definition">Definition at line <a class="el" href="_neural_net_feed_forward_8cpp_source.html#l00191">191</a> of file <a class="el" href="_neural_net_feed_forward_8cpp_source.html">NeuralNetFeedForward.cpp</a>.</p>

</div>
</div>
<a id="a703b5d1758980e9365bd3be29525dd68" name="a703b5d1758980e9365bd3be29525dd68"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a703b5d1758980e9365bd3be29525dd68">&#9670;&#160;</a></span>update()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">std::vector&lt; double &gt; DCL::CNeuralNetworkFeedForward::update </td>
          <td>(</td>
          <td class="paramtype">std::vector&lt; double &gt; &amp;</td>          <td class="paramname"><span class="paramname"><em>vecInputs</em></span></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Given a vector of inputs, updates the neural network and returns the output values. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">vecInputs</td><td>A vector holding each of the input values for the network. </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>A vector of doubles holding the output values of the network.</dd></dl>
<p>If invalid number of inputs is given, an exception occurs </p>

<p class="definition">Definition at line <a class="el" href="_neural_net_feed_forward_8cpp_source.html#l00142">142</a> of file <a class="el" href="_neural_net_feed_forward_8cpp_source.html">NeuralNetFeedForward.cpp</a>.</p>

</div>
</div>
<hr/>The documentation for this class was generated from the following files:<ul>
<li>X:/Projects/c++/2024/DCP/ProjectFiles/StaticLibs/DavesCodeLib/ArtificialIntelligence/<a class="el" href="_neural_net_feed_forward_8h_source.html">NeuralNetFeedForward.h</a></li>
<li>X:/Projects/c++/2024/DCP/ProjectFiles/StaticLibs/DavesCodeLib/ArtificialIntelligence/<a class="el" href="_neural_net_feed_forward_8cpp_source.html">NeuralNetFeedForward.cpp</a></li>
</ul>
</div><!-- contents -->
</div><!-- doc-content -->
<!-- start footer part -->
<div id="nav-path" class="navpath"><!-- id is needed for treeview function! -->
  <ul>
    <li class="navelem"><a class="el" href="namespace_d_c_l.html">DCL</a></li><li class="navelem"><a class="el" href="class_d_c_l_1_1_c_neural_network_feed_forward.html">CNeuralNetworkFeedForward</a></li>
    <li class="footer">Generated by <a href="https://www.doxygen.org/index.html"><img class="footer" src="doxygen.svg" width="104" height="31" alt="doxygen"/></a> 1.11.0 </li>
  </ul>
</div>
</body>
</html>
